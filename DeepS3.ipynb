{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1d7b70dd",
   "metadata": {},
   "source": [
    "### Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26c41b58",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf2\n",
    "from tensorflow.keras import layers\n",
    "import numpy as np \n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.initializers import glorot_uniform\n",
    "\n",
    "import rasterio\n",
    "from rasterio.plot import show\n",
    "from rasterio.merge import merge\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e04dd63e",
   "metadata": {},
   "source": [
    "### Load DeepS3 Model and Weights\n",
    "Loads on all available GPUs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebf46e63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a MirroredStrategy.\n",
    "strategy = tf2.distribute.MirroredStrategy()\n",
    "print('Number of devices: {}'.format(strategy.num_replicas_in_sync))\n",
    "\n",
    "crop_classes = 9\n",
    "num_covars = 16\n",
    "\n",
    "\n",
    "# Open a strategy scope.\n",
    "with strategy.scope():\n",
    "\n",
    "    def production_estimate(covariates, classes=crop_classes, name='prod_est'):   \n",
    "        X = covariates\n",
    "\n",
    "        X = layers.Dense(256, activation=None, name='fc1', kernel_initializer = glorot_uniform())(X)\n",
    "        X = layers.BatchNormalization(name='batch_norm1')(X)\n",
    "        X = layers.Activation('relu')(X)\n",
    "        X = layers.Dropout(0.95, name='dropout1')(X)\n",
    "\n",
    "        X = layers.Dense(512, activation=None, name='fc2', kernel_initializer = glorot_uniform())(X)\n",
    "        X = layers.BatchNormalization(name='batch_norm2')(X)\n",
    "        X = layers.Activation('relu')(X)\n",
    "        X = layers.Dropout(0.95, name='dropout2')(X)\n",
    "\n",
    "        X = layers.Dense(256, activation=None, name='fc3', kernel_initializer = glorot_uniform())(X)\n",
    "        X = layers.BatchNormalization(name='batch_norm3')(X)\n",
    "        X = layers.Activation('relu')(X)\n",
    "        X = layers.Dropout(0.95, name='dropout3')(X)\n",
    "\n",
    "        X = layers.Dense(classes, activation=None, name='fc4', kernel_initializer = glorot_uniform())(X)\n",
    "        return X\n",
    "\n",
    "    input_covars = layers.Input((num_covars)) \n",
    "    prod_estimate = production_estimate(input_covars)\n",
    "    production_estimate_model = Model([input_covars], prod_estimate)\n",
    "\n",
    "    yield_estimate = production_estimate_model([input_covars])/17\n",
    "\n",
    "    newmodel = Model([input_covars], [yield_estimate])\n",
    "\n",
    "    newmodel.compile()\n",
    "    newmodel.load_weights('./saved_weights6') "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49bcff7c",
   "metadata": {},
   "source": [
    "# Generate Change in Land Suitability Images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99bc98f3",
   "metadata": {},
   "source": [
    "#### Step 1: Load images and normalize\n",
    "For this demonstration, the '.tif' images are not included to conserve storage space. The order of the soil-climate-landscape bands must be: \n",
    "\n",
    "1: precipitation1\n",
    "\n",
    "2: precipitation2\n",
    "\n",
    "3: precipitation3\n",
    "\n",
    "4: max1\n",
    "\n",
    "5: max2\n",
    "\n",
    "6: max3\n",
    "\n",
    "7: diurnal1\n",
    "\n",
    "8: diurnal2\n",
    "\n",
    "9: diurnal3\n",
    "\n",
    "10: Slope\n",
    "\n",
    "11: Aspect\n",
    "\n",
    "12: Soil water content\n",
    "\n",
    "13: Organic Carbon\n",
    "\n",
    "14: pH\n",
    "\n",
    "15: Bulk density\n",
    "\n",
    "16: Texture\n",
    "\n",
    "See https://www.nature.com/articles/s41598-023-33840-6 for variable name definitions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2445b7de",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = ['rcp45_2100', 'rcp85_2100', 'rcp45_2050', 'rcp85_2050', \n",
    "         '2013', '2014', '2015', '2016', '2017', '2018', '2019', '2020']\n",
    "\n",
    "for file in files:\n",
    "    # Dynamic images hold the climate variables as they change with time\n",
    "    dynamic1 = './Canada_images/Canada_'+file+'_dynamic1.tif'\n",
    "    dynamic1 = rasterio.open(dynamic1)\n",
    "    dynamic1 = np.nan_to_num(dynamic1.read(), nan=0)[1:]\n",
    "    print('dynamic1: ', dynamic1.shape)\n",
    "\n",
    "    dynamic2 = './Canada_images/Canada_'+file+'_dynamic2.tif'\n",
    "    dynamic2 = rasterio.open(dynamic2)\n",
    "    dynamic2 = np.nan_to_num(dynamic2.read(), nan=0)[1:]\n",
    "    print('dynamic2: ', dynamic2.shape)\n",
    "\n",
    "    dynamic3 = './Canada_images/Canada_'+file+'_dynamic3.tif'\n",
    "    dynamic3 = rasterio.open(dynamic3)\n",
    "    dynamic3 = np.nan_to_num(dynamic3.read(), nan=0)[1:4]\n",
    "    print('dynamic3: ', dynamic3.shape)\n",
    "\n",
    "    # Fixed images hold the soil and landscape variables and are approximated to not change with time\n",
    "    fixed = './Canada_images/Canada_fixed.tif'\n",
    "    fixed = rasterio.open(fixed)\n",
    "    fixed = np.nan_to_num(fixed.read(), nan=0)[1:]\n",
    "    print('fixed: ', fixed.shape)\n",
    "\n",
    "    texture = './Canada_images/Canada_texture.tif'\n",
    "    texture = rasterio.open(texture)\n",
    "    texture = np.nan_to_num(texture.read(), nan=0)[1:]\n",
    "    print('texture: ', texture.shape)\n",
    "\n",
    "\n",
    "    image_bands = np.concatenate((dynamic1, dynamic2, dynamic3, fixed, texture), axis=0)\n",
    "    image_bands = np.rollaxis(image_bands, 0, 3)\n",
    "    print(image_bands.shape)\n",
    "\n",
    "\n",
    "    # Normalization constants for each of the 16 soil-climate-landscape bands\n",
    "    means = [0.03551382256849559, 0.08073814755983579, 0.07639564565353554, 255.76399219409984, 270.2168567496686, 272.93352017273264, 8.307632100554585, 10.43708781750244, 11.072088704221276, 0.3764292019779276, 158.30607690957885, 27.16255910753614, 3.244099755851966, 70.87902882024018, 143.29658599994613, 5.881678519373872]\n",
    "    stds = [0.03349792720149147, 0.048172183329598196, 0.04071408897960723, 53.32938195633493, 58.93709074469724, 60.012230286558, 0.9392917921457363, 1.1716698780527741, 1.6298420259844137, 0.409656212302975, 103.72171860972377, 2.791000038139096, 3.340814105627918, 3.8674299038985436, 10.029818223885423, 1.732019506485493]\n",
    "    \n",
    "    for i in range(0, 16):\n",
    "        image_bands[:, :, i] = (image_bands[:, :, i] - means[i])/stds[i]\n",
    "\n",
    "    with open('Canada_'+file+'.pickle', 'wb') as handle:\n",
    "        pickle.dump(image_bands, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b1ab5be",
   "metadata": {},
   "source": [
    "#### Step 2: \n",
    "* Predict land suitability annually from 2013 to 2020, as well as for future scenarios, by providing the corresponding set of images to DeepS3 as input.\n",
    "\n",
    "\n",
    "* For each set of input images, the output will be 9 images, each representing the land suitability of a different crop in the following order: 'Barley', 'Canola', 'Corn for grain', 'Flaxseed', 'Oats', 'Dry Peas', 'Soybeans', 'Triticale', and 'Spring Wheat'.\n",
    "\n",
    "\n",
    "#### Step 3:\n",
    "* Calculate an image that reflects the baseline land suitability for each type of crop by averaging the suitability scores from 2013 to 2020 for each individual crop. Upon completion, you will have nine images, with each one depicting the mean land suitability for a specific crop for the present time.\n",
    "\n",
    "\n",
    "\n",
    "#### Step 4:\n",
    "* Calculate the percent change in land suitability for each future scenario via:\n",
    "$$ \n",
    "\\Delta \\text{Suitability}_{\\text{climate scenario, year, crop}} = \\frac{\\text{Suitability}_{\\text{climate scenario, year, crop}} - \\text{Suitability}_{\\text{baseline, crop}}}{\\text{Suitability}_{\\text{baseline, crop}}},\n",
    "$$\n",
    "\n",
    "where $\\text{Suitability}_{\\text{climate scenario, year, crop}}$ is the future climate scenerio crop suitability predicted in Step 1, and $\\text{Suitability}_{\\text{baseline, crop}}$ is the baseline suitability calculated in Step 2.\n",
    "\n",
    "\n",
    "* Once this step is finalized, you can transform the array into a map using mapping software such as QGIS.\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
